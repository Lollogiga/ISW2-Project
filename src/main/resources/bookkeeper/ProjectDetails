//AFeatures = LOC/Cyclomatic Complexity
//BClassifier = random Forest
//AFMethod = bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java::flushLedger
//Method Before refactoring =
private void flushLedger(long l) throws IOException {
        LinkedList<Long> firstEntryList;
        synchronized(this) {
            HashMap<Long, LedgerEntryPage> pageMap = pages.get(l);
            if (pageMap == null || pageMap.isEmpty()) {
                FileInfo fi = null;
                try {
                    fi = getFileInfo(l, null);
                    fi.flushHeader();
                } finally {
                    if (null != fi) {
                        fi.release();
                    }
                }
                return;
            }
            firstEntryList = new LinkedList<Long>();
            for(Map.Entry<Long, LedgerEntryPage> entry: pageMap.entrySet()) {
                LedgerEntryPage lep = entry.getValue();
                if (lep.isClean()) {
                    LOG.trace("Page is clean {}", lep);
                    continue;
                }
                firstEntryList.add(lep.getFirstEntry());
            }
        }

        if (firstEntryList.size() == 0) {
            LOG.debug("Nothing to flush for ledger {}.", l);
            // nothing to do
            return;
        }

        // Now flush all the pages of a ledger
        List<LedgerEntryPage> entries = new ArrayList<LedgerEntryPage>(firstEntryList.size());
        FileInfo fi = null;
        try {
            for(Long firstEntry: firstEntryList) {
                LedgerEntryPage lep = getLedgerEntryPage(l, firstEntry, true);
                if (lep != null) {
                    entries.add(lep);
                }
            }
            Collections.sort(entries, new Comparator<LedgerEntryPage>() {
                    @Override
                    public int compare(LedgerEntryPage o1, LedgerEntryPage o2) {
                    return (int)(o1.getFirstEntry()-o2.getFirstEntry());
                    }
                    });
            ArrayList<Integer> versions = new ArrayList<Integer>(entries.size());
            fi = getFileInfo(l, null);
            // flush the header if necessary
            fi.flushHeader();
            int start = 0;
            long lastOffset = -1;
            for(int i = 0; i < entries.size(); i++) {
                versions.add(i, entries.get(i).getVersion());
                if (lastOffset != -1 && (entries.get(i).getFirstEntry() - lastOffset) != entriesPerPage) {
                    // send up a sequential list
                    int count = i - start;
                    if (count == 0) {
                        LOG.warn("Count cannot possibly be zero!");
                    }
                    writeBuffers(l, entries, fi, start, count);
                    start = i;
                }
                lastOffset = entries.get(i).getFirstEntry();
            }
            if (entries.size()-start == 0 && entries.size() != 0) {
                LOG.warn("Nothing to write, but there were entries!");
            }
            writeBuffers(l, entries, fi, start, entries.size()-start);
            synchronized(this) {
                for(int i = 0; i < entries.size(); i++) {
                    LedgerEntryPage lep = entries.get(i);
                    lep.setClean(versions.get(i));
                }
            }
        } finally {
            for(LedgerEntryPage lep: entries) {
                lep.releasePage();
            }
            if (fi != null) {
                fi.release();
            }
        }
    }

//Method After refactoring

private void flushLedger(long l) throws IOException {
    // 1) raccogli le pagine "dirty" (o flush solo header se non ce ne sono)
    List<Long> firstEntryList = collectDirtyFirstEntriesOrFlushHeader(l);
    if (firstEntryList.isEmpty()) {
        LOG.debug("Nothing to flush for ledger {}.", l);
        return;
    }

    // 2) carica le pagine effettive da scrivere e le relative versioni
    List<LedgerEntryPage> entries = new ArrayList<>(firstEntryList.size());
    List<Integer> versions = new ArrayList<>(firstEntryList.size());
    loadDirtyPages(l, firstEntryList, entries, versions);

    if (entries.isEmpty()) {
        LOG.debug("No pages loaded for ledger {}.", l);
        return;
    }

    // 3) ordina per firstEntry
    entries.sort((o1, o2) -> Long.compare(o1.getFirstEntry(), o2.getFirstEntry()));

    FileInfo fi = null;
    try {
        fi = getFileInfo(l, null);
        fi.flushHeader(); // flush header se necessario

        // 4) flusha a "runs" contigue (batch)
        flushSequentialRuns(l, entries, fi);

        // 5) marca pulite mantenendo la versione coerente
        markClean(entries, versions);
    } finally {
        // 6) release risorse
        releaseAll(entries, fi);
    }
}

/* ===================== Helpers (privati) ===================== */

private List<Long> collectDirtyFirstEntriesOrFlushHeader(long l) throws IOException {
    HashMap<Long, LedgerEntryPage> pageMap;
    List<Long> firstEntryList = new LinkedList<>();
    synchronized (this) {
        pageMap = pages.get(l);
        if (pageMap == null || pageMap.isEmpty()) {
            // Niente pagine: flush del solo header
            flushHeaderOnly(l);
            return firstEntryList;
        }
        for (Map.Entry<Long, LedgerEntryPage> e : pageMap.entrySet()) {
            LedgerEntryPage lep = e.getValue();
            if (lep.isClean()) {
                LOG.trace("Page is clean {}", lep);
                continue;
            }
            firstEntryList.add(lep.getFirstEntry());
        }
    }
    return firstEntryList;
}

private void flushHeaderOnly(long l) throws IOException {
    FileInfo fi = null;
    try {
        fi = getFileInfo(l, null);
        fi.flushHeader();
    } finally {
        if (fi != null) fi.release();
    }
}

private void loadDirtyPages(long l,
                            List<Long> firstEntryList,
                            List<LedgerEntryPage> outEntries,
                            List<Integer> outVersions) throws IOException {
    for (Long firstEntry : firstEntryList) {
        LedgerEntryPage lep = getLedgerEntryPage(l, firstEntry, true);
        if (lep != null) {
            outEntries.add(lep);
            outVersions.add(lep.getVersion());
        }
    }
}

private void flushSequentialRuns(long l,
                                 List<LedgerEntryPage> entries,
                                 FileInfo fi) throws IOException {
    int start = 0;
    long lastOffset = -1;

    for (int i = 0; i < entries.size(); i++) {
        long first = entries.get(i).getFirstEntry();

        boolean contiguous = (lastOffset == -1)
                || ((first - lastOffset) == entriesPerPage);

        if (!contiguous) {
            int count = i - start;
            if (count == 0) {
                LOG.warn("Count cannot possibly be zero!");
            } else {
                writeBuffers(l, entries, fi, start, count);
            }
            start = i;
        }
        lastOffset = first;
    }

    int tail = entries.size() - start;
    if (tail == 0 && !entries.isEmpty()) {
        LOG.warn("Nothing to write, but there were entries!");
    }
    if (tail > 0) {
        writeBuffers(l, entries, fi, start, tail);
    }
}

private void markClean(List<LedgerEntryPage> entries, List<Integer> versions) {
    synchronized (this) {
        for (int i = 0; i < entries.size(); i++) {
            entries.get(i).setClean(versions.get(i));
        }
    }
}

private void releaseAll(List<LedgerEntryPage> entries, FileInfo fi) {
    for (LedgerEntryPage lep : entries) {
        lep.releasePage();
    }
    if (fi != null) {
        fi.release();
    }
}


NewFeatures:
"LOC","CyclomaticComplexity","Churn","LocAdded","fan-in","fan-out","NewcomerRisk","Auth","WeekendCommit","nSmell","isBuggy"
36, 4, 58, 90, 0, 12, 1, 2, 0, 3

Effettivamente facendo il refactoring riesco a diminuire non solo il LOC che è la variabile che voleva o diminuire, ma in tal modo andiamo a diminuire anche
altro che era correlato positivemente con la buggyness. Di contro Aumentano anche metriche che sono correlate con la buggyness. Infine si creano diversi metodi in più.


